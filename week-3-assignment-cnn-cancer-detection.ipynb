{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11848,"databundleVersionId":862157,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport numpy as np\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n    # for filename in filenames:\n        # print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-17T14:33:39.307357Z","iopub.execute_input":"2025-06-17T14:33:39.307873Z","iopub.status.idle":"2025-06-17T14:33:40.198698Z","shell.execute_reply.started":"2025-06-17T14:33:39.307851Z","shell.execute_reply":"2025-06-17T14:33:40.197946Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# os.remove(\"/kaggle/working/best_basic_model.keras\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T14:34:45.179756Z","iopub.execute_input":"2025-06-17T14:34:45.180493Z","iopub.status.idle":"2025-06-17T14:34:45.184322Z","shell.execute_reply.started":"2025-06-17T14:34:45.180465Z","shell.execute_reply":"2025-06-17T14:34:45.183522Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Introduction - CNN Cancer Detection\n\nIn this notebook, we will be working with the Histopathologic Cancer Detection dataset from Cukierski (2018), which is a modified subset of PatchCamelyon (PCam) with all duplicates removed. The goal of this project is to train a model that can predict whether the center 32×32 pixel region of an image patch contains at least one pixel of tumor tissue.\n\nThe project includes problem explanation, exploratory data analysis (EDA), data preprocessing, model building, hyperparameter tuning, results analysis, and conclusion.\n\n","metadata":{}},{"cell_type":"markdown","source":"# Part 1 -  Description of the problem and data\n\n**The Problem**\n\nThe objective is to classify histopathologic images as either cancerous (label = 1) or non-cancerous (label = 0) by analyzing a 32×32 pixel region within each 96×96 pixel image. The dataset includes over 220,000 training images and 57,000 test images in .tif format. This is a binary classification task that involves training a deep learning model to accurately identify cancerous areas.\n\n**The Data**\n\nThe dataset is composed by:\n\n- Training Labels: A CSV file (train_labels.csv) containing image IDs along with corresponding binary labels — 1 for cancerous and 0 for non-cancerous.\n\n- Training Images: Around 220,000 RGB images, each sized 96×96 pixels, stored in the train directory.\n\n- Test Images: Roughly 57,000 unlabeled images of the same size and format, located in the test directory.\n\n- Labeling Focus: Each label refers specifically to the presence or absence of tumor tissue in the central 32×32 region of the image.\n\n\n\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# Part 2 - Exploratory Data Analysis (EDA) — Inspect, Visualize and Clean the Data\n\nWe now want to understand the data more. Let's start by exploring some basic data description.","metadata":{}},{"cell_type":"code","source":"# Define the paths for data\ndata_dir = '/kaggle/input/histopathologic-cancer-detection/'\ntrain_labels_path = os.path.join(data_dir, 'train_labels.csv')\ntrain_images = os.path.join(data_dir, 'train')\ntest_images = os.path.join(data_dir, 'test')\n\n# Load the labels\ntrain_labels = pd.read_csv(train_labels_path)\n\n# Data description\nprint(f\"Train labels shape: {train_labels.shape}\")\nprint(\"\\nDistribution of the labels:\")\nprint(train_labels['label'].value_counts())\nprint(\"\\nFirst 5 rows of training labels:\")\nprint(train_labels.head())\nprint(\"\\nMissing values:\")\nprint(train_labels.isnull().sum())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We also want to visualize the label distribution to see if there is any possible imbalance.\n\n","metadata":{}},{"cell_type":"code","source":"label_counts = train_labels['label'].value_counts()\ntotal = len(train_labels)\n\n# Visualize\nplt.figure(figsize=(6,4))\nax = sns.countplot(data=train_labels, x='label')\n\nfor p in ax.patches:\n    count = p.get_height()\n    percent = f'{100 * count / total:.2f}%'\n    x = p.get_x() + p.get_width() / 2\n    y = p.get_height()\n    ax.text(x, y + total * 0.01, percent, ha='center', va='bottom', fontsize=12)\n\nplt.title(\"Label Distribution (0: Non-Cancerous 1: Cancerous)\")\nplt.xlabel(\"Label\")\nplt.ylabel(\"Count\")\nplt.ylim(0, label_counts.max() * 1.1)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can determine the actual dimensions of an image by using its 'shape' attribute, which provides the width, height, and number of channels (RGB).","metadata":{}},{"cell_type":"code","source":"def load_images(image_id, base_path='/kaggle/input/histopathologic-cancer-detection/train'):\n    path = os.path.join(base_path, f\"{image_id}.tif\")\n    return cv2.imread(path)\n\ndef show_samples(train_labels, label, n=4):\n    samples = train_labels[train_labels['label'] == label].sample(n)\n    fig, axes = plt.subplots(1, n, figsize=(15, 5))\n    for img_id, ax in zip(samples['id'], axes):\n        img = load_images(img_id)\n        ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n        ax.axis('off')\n    plt.suptitle(f\"Label: {label} (0: Non-Cancerous, 1: Cancerous)\")\n    plt.show()\n\nshow_samples(train_labels, label=0)\nshow_samples(train_labels, label=1)\n\nimg = load_images(train_labels['id'][0])\nprint(\"Image shape:\", img.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**EDA Summary: Insights & Data Cleaning**\n\n***Label Distribution***\n* The dataset consists of approximately 60% non-cancerous (label=0) and 40% cancerous (label=1) images.\n* This indicates a moderate class imbalance, which might affect model performance, especially in terms of recall and precision for the minority class (cancerous).\n* We'll consider using class weighting, balanced sampling, or augmentation for label=1 during training.\n\n***Data Integrity***\n* No missing values were found in the train_labels.csv.\n\n* All image IDs in the CSV appear valid and point to existing .tif files.\n\n***Visual Inspection***\n\n* Sample images from both classes are visually diverse.\n\n* Cancerous patches don't always show clearly distinct features, which means the model will need to learn subtle texture or color patterns.\n\n* Non-cancerous samples sometimes contain tissue that looks similar to cancerous ones, so false positives could be an issue.\n\n***Need for Data Cleaning?***\n\nNo major cleaning needed:\n\n* Labels are binary and well-defined.\n\n* Image files are accessible and not corrupted (at least in the samples tested).","metadata":{}},{"cell_type":"markdown","source":"# Part 3 - Data Preprocessing & Plan of Analysis\n","metadata":{}},{"cell_type":"markdown","source":"**Splitting the dataset**\n\nBefore training our models, we need to split the data into training and validation sets. To avoid overloading Kaggle’s memory, we first take a smaller sample of the dataset. I chose 30,000 samples to keep the process faster and more manageable during model development. Using this sampled data, we then create the train/validation split to prepare for training.","metadata":{}},{"cell_type":"markdown","source":"**To prepare for image import, we add a column for the full filename (including the extension) and convert the label to a string format.**","metadata":{}},{"cell_type":"code","source":"train_labels['label_str'] = train_labels['label'].astype(str)\ntrain_labels['filename'] = train_labels['id'] + '.tif'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Sample 30,000 entries from train_labels, keeping label distribution balanced\ndf_sampled, _ = train_test_split(\n    train_labels,\n    train_size=30000,\n    stratify=train_labels['label'],\n    random_state=42\n)\n\n# Split sampled data into training (80%) and validation (20%) sets with stratification\ntrain_df, val_df = train_test_split(\n    df_sampled,\n    test_size=0.2,                      # 20% reserved for validation\n    stratify=df_sampled['label'],       # maintain class balance in splits\n    random_state=42                     # ensure reproducibility\n)\n\n# Show label distribution to confirm balance in training and validation sets\nprint(\"Train label distribution:\")\nprint(train_df['label'].value_counts(normalize=True))\n\nprint(\"\\nValidation label distribution:\")\nprint(val_df['label'].value_counts(normalize=True))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Load, resize, convert, and normalize images, then create TensorFlow datasets using a custom generator for efficient training and validation.**","metadata":{}},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport tensorflow as tf\n\nBATCH_SIZE = 32\nIMAGE_SIZE = (96, 96)\n\ndef preprocess_image(image_path):\n    # Load the image in BGR format\n    image = cv2.imread(image_path)\n    # Resize to fixed size\n    image = cv2.resize(image, IMAGE_SIZE)\n    # Convert BGR to RGB color space\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    # Normalize pixel values to [0, 1]\n    image = image.astype(np.float32) / 255.0\n    return image\n\ndef create_data_generator(image_paths, labels):\n    for img_path, lbl in zip(image_paths, labels):\n        img = preprocess_image(img_path)\n        yield img, lbl\n\n# Prepare file paths and labels for training and validation sets\ntrain_image_paths = [f\"/kaggle/input/histopathologic-cancer-detection/train/{filename}\" for filename in train_df['filename']]\ntrain_labels = train_df['label'].values.astype(np.float32)\n\nval_image_paths = [f\"/kaggle/input/histopathologic-cancer-detection/train/{filename}\" for filename in val_df['filename']]\nval_labels = val_df['label'].values.astype(np.float32)\n\n# Create TensorFlow datasets using your generator function\ntrain_dataset = tf.data.Dataset.from_generator(\n    lambda: create_data_generator(train_image_paths, train_labels),\n    output_signature=(\n        tf.TensorSpec(shape=(*IMAGE_SIZE, 3), dtype=tf.float32),\n        tf.TensorSpec(shape=(), dtype=tf.float32)\n    )\n).shuffle(1000).repeat().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\nval_dataset = tf.data.Dataset.from_generator(\n    lambda: create_data_generator(val_image_paths, val_labels),\n    output_signature=(\n        tf.TensorSpec(shape=(*IMAGE_SIZE, 3), dtype=tf.float32),\n        tf.TensorSpec(shape=(), dtype=tf.float32)\n    )\n).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Data sanity check**","metadata":{}},{"cell_type":"code","source":"# Take one batch from the training dataset\nfor images, labels in train_dataset.take(1):\n    print(\"Image batch shape:\", images.shape)\n    print(\"Label batch shape:\", labels.shape)\n    print(\"First label in batch:\", labels[0].numpy())\n    break","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Part 4 - Model Architecture\n\nWe will use both the basic model and the VGG model for the model architecture section. These models will help us compare simple versus more complex convolutional neural networks. This approach allows us to understand their performance differences on our dataset.","metadata":{}},{"cell_type":"markdown","source":"**Model 1: Basic Model with Batch Normalization**\n\nThis is a simple convolutional neural network that gradually extracts features from images using convolutional layers. It uses batch normalization and max pooling to stabilize training and reduce spatial size. The model ends with dense layers to perform binary classification.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\ndef build_basic_cnn(input_shape=(96, 96, 3)):\n    model = models.Sequential([\n        layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=input_shape),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2,2)),\n        \n        layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2,2)),\n\n        layers.Flatten(),\n        layers.BatchNormalization(),\n        layers.Dropout(0.5),\n        \n        layers.Dense(1, activation='sigmoid')  # Binary classification\n    ], name=\"Basic_CNN_Model\")\n    return model\n\nbasic_model = build_basic_cnn()\nbasic_model.summary()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Model 2: VGGNet**\n\n\nThis model is inspired by the VGG architecture and uses multiple convolutional layers per block to learn more complex features. Batch normalization is applied after each convolution to improve training stability. Max pooling layers reduce spatial dimensions progressively. Dense layers at the end perform binary classification based on the extracted high-level features.","metadata":{}},{"cell_type":"code","source":"def build_vgg_like(input_shape=(96, 96, 3)):\n    model = models.Sequential([\n        layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=input_shape),\n        layers.BatchNormalization(),\n        layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2,2)),\n        \n        layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2,2)),\n        \n        layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2,2)),\n\n        layers.Flatten(),\n        layers.Dense(256, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(1, activation='sigmoid')  # Binary classification\n    ], name=\"vgg_like_model\")\n    return model\n\nvgg_model = build_vgg_like()\nvgg_model.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Part 5 - Results and Analysis\n\nWe will start by training the basic CNN model and evaluating it using the confusion matrix, AUC, and false negative rate, which is critical for medical data. Then, we apply the same process to the VGG-style model to compare performance. Finally, we tune the best model's optimizer, loss function, and other settings. All models use a fixed steps per epoch for consistent training.\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import callbacks\n\n# Compile the model\nbasic_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nsteps_per_epoch = len(train_df) // BATCH_SIZE\nvalidation_steps = len(val_df) // BATCH_SIZE\n\ncallbacks_list = [\n    callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=1),\n    callbacks.ModelCheckpoint(filepath='best_basic_model.keras', monitor='val_accuracy', save_best_only=True, verbose=1)\n]\n\nbm_history = basic_model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=10,\n    steps_per_epoch=steps_per_epoch,\n    validation_steps=validation_steps,\n    callbacks=callbacks_list,\n    verbose=2\n)\n\nbasic_model.evaluate(val_dataset, steps=validation_steps)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"After running the first basic model, we can plot the accuracy and loss history.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Accuracy plot\nplt.figure(figsize=(10, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(bm_history.history['accuracy'], label='Train Accuracy')\nplt.plot(bm_history.history['val_accuracy'], label='Val Accuracy')\nplt.title('Basic Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Loss plot\nplt.subplot(1, 2, 2)\nplt.plot(bm_history.history['loss'], label='Train Loss')\nplt.plot(bm_history.history['val_loss'], label='Val Loss')\nplt.title('Basic Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The model is learning, as shown by the overall upward trend in validation accuracy. However, the fluctuations suggest unstable training, which could be caused by a high learning rate, a small or noisy validation set, or slight overfitting. To improve stability, we can continue training with early stopping, allow the learning rate scheduler to adjust, and consider adding dropout or other regularization techniques. \n\nNext we want to get the predicted and true values for the labels which is useful for creating confusion matrix and AUC.","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef get_y_true_and_y_pred(val_dataset, model, threshold=0.5):\n    y_true = []\n    y_pred_probs = []\n\n    for batch_x, batch_y in val_dataset:\n        preds = model.predict(batch_x, verbose=0)\n        y_pred_probs.extend(preds.ravel())  # Flatten predicted probabilities\n        y_true.extend(batch_y.numpy().ravel())  # Convert labels from tensor to NumPy array\n\n    y_true = np.array(y_true)\n    y_pred_probs = np.array(y_pred_probs)\n    y_pred = (y_pred_probs > threshold).astype(int)\n\n    return y_true, y_pred, y_pred_probs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_true_bm, y_pred_bm, y_pred_probs_bm = get_y_true_and_y_pred(val_dataset, basic_model, threshold=0.5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\n# Confusion Matrix\ncm = confusion_matrix(y_true_bm, y_pred_bm)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot(cmap='Blues')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The confusion matrix shows that there are a decent amount of false negatives, which is not great for medical projects since every prediction will matter a lot.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\n\n\nfpr, tpr, _ = roc_curve(y_true_bm, y_pred_probs_bm)\nroc_auc = auc(fpr, tpr)\n\nplt.figure()\nplt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], linestyle='--', color='gray')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate (Recall)')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc='lower right')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The ROC curve plot shows that the AUC is 0.89.","metadata":{}},{"cell_type":"code","source":"vgg_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nsteps_per_epoch = len(train_df) // BATCH_SIZE\nvalidation_steps = len(val_df) // BATCH_SIZE\n\ncallbacks_list_vgg = [\n    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=1),\n    tf.keras.callbacks.ModelCheckpoint(filepath='best_vgg_model.keras', monitor='val_accuracy', save_best_only=True, verbose=1)\n]\n\nvgg_history = vgg_model.fit(\n    train_dataset,  \n    validation_data=val_dataset,\n    epochs=10,\n    steps_per_epoch=steps_per_epoch,\n    validation_steps=validation_steps,\n    callbacks=callbacks_list_vgg,\n    verbose=2\n)\n\nvgg_model.evaluate(val_dataset, steps=validation_steps)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Accuracy plot\nplt.figure(figsize=(10, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(vgg_history.history['accuracy'], label='Train Accuracy')\nplt.plot(vgg_history.history['val_accuracy'], label='Val Accuracy')\nplt.title('vgg_liked_Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Loss plot\nplt.subplot(1, 2, 2)\nplt.plot(vgg_history.history['loss'], label='Train Loss')\nplt.plot(vgg_history.history['val_loss'], label='Val Loss')\nplt.title('vgg_liked_Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_true_vgg, y_pred_vgg, y_pred_probs_vgg = get_y_true_and_y_pred(val_dataset, vgg_model, 0.5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ncm = confusion_matrix(y_true_vgg, y_pred_vgg)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot(cmap='Blues')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\n\nfpr, tpr, _ = roc_curve(y_true_vgg, y_pred_probs_vgg)\nroc_auc = auc(fpr, tpr)\n\nplt.figure()\nplt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], linestyle='--', color='gray')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate (Recall)')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc='lower right')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Tuning Parameter: VGGNet Model - Learning Rate\n","metadata":{}},{"cell_type":"code","source":"# Create TensorFlow datasets using your generator function\ntrain_dataset = tf.data.Dataset.from_generator(\n    lambda: create_data_generator(train_image_paths, train_labels),\n    output_signature=(\n        tf.TensorSpec(shape=(*IMAGE_SIZE, 3), dtype=tf.float32),\n        tf.TensorSpec(shape=(), dtype=tf.float32)\n    )\n).shuffle(1000).repeat().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\nval_dataset = tf.data.Dataset.from_generator(\n    lambda: create_data_generator(val_image_paths, val_labels),\n    output_signature=(\n        tf.TensorSpec(shape=(*IMAGE_SIZE, 3), dtype=tf.float32),\n        tf.TensorSpec(shape=(), dtype=tf.float32)\n    )\n).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models, callbacks\n\n# Use a lower learning rate for fine-tuning\nnew_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n\n# Compile the VGG model\nvgg_model.compile(\n    optimizer=new_optimizer,\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\n# Callbacks\ncallbacks_list = [\n    callbacks.EarlyStopping(\n        monitor='val_loss',\n        patience=3,\n        restore_best_weights=True\n    ),\n    callbacks.ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.2,\n        patience=3,\n        min_lr=1e-6\n    ),\n    callbacks.ModelCheckpoint(\n        filepath='best_vgg_model_v1.keras',\n        monitor='val_accuracy',\n        save_best_only=True,\n        verbose=1\n    )\n]\n\n# Compute steps per epoch\nsteps_per_epoch = len(train_df) // BATCH_SIZE\nvalidation_steps = len(val_df) // BATCH_SIZE\n\n# Train the model\nvgg_history_v2 = vgg_model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=10,\n    steps_per_epoch=steps_per_epoch,\n    validation_steps=validation_steps,\n    callbacks=callbacks_list,\n    verbose=2\n)\n\n# Evaluate the model\nvgg_model.evaluate(val_dataset, steps=validation_steps)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Accuracy plot\nplt.figure(figsize=(10, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(vgg_history_v2.history['accuracy'], label='Train Accuracy')\nplt.plot(vgg_history_v2.history['val_accuracy'], label='Val Accuracy')\nplt.title('vgg_v2_Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Loss plot\nplt.subplot(1, 2, 2)\nplt.plot(vgg_history_v2.history['loss'], label='Train Loss')\nplt.plot(vgg_history_v2.history['val_loss'], label='Val Loss')\nplt.title('vgg_v2_Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Tuning Parameter: VGGNet Model - L2 Regularization","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import regularizers\n\ndef build_vgg_like_l2(input_shape=(96, 96, 3), l2_lambda=1e-4):\n    l2 = regularizers.l2(l2_lambda)\n\n    model = models.Sequential([\n        layers.Conv2D(32, (3,3), activation='relu', padding='same', kernel_regularizer=l2, input_shape=input_shape),\n        layers.BatchNormalization(),\n        layers.Conv2D(32, (3,3), activation='relu', padding='same', kernel_regularizer=l2),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2,2)),\n\n        layers.Conv2D(64, (3,3), activation='relu', padding='same', kernel_regularizer=l2),\n        layers.BatchNormalization(),\n        layers.Conv2D(64, (3,3), activation='relu', padding='same', kernel_regularizer=l2),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2,2)),\n\n        layers.Conv2D(128, (3,3), activation='relu', padding='same', kernel_regularizer=l2),\n        layers.BatchNormalization(),\n        layers.Conv2D(128, (3,3), activation='relu', padding='same', kernel_regularizer=l2),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2,2)),\n\n        layers.Flatten(),\n        layers.Dense(256, activation='relu', kernel_regularizer=l2),\n        layers.Dropout(0.5),\n        layers.Dense(1, activation='sigmoid')\n    ], name=\"vgg_like_l2\")\n    \n    return model\n\nvgg_model_l2 = build_vgg_like_l2()\nvgg_model_l2.summary()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create TensorFlow datasets using your generator function\ntrain_dataset = tf.data.Dataset.from_generator(\n    lambda: create_data_generator(train_image_paths, train_labels),\n    output_signature=(\n        tf.TensorSpec(shape=(*IMAGE_SIZE, 3), dtype=tf.float32),\n        tf.TensorSpec(shape=(), dtype=tf.float32)\n    )\n).shuffle(1000).repeat().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\n\nval_dataset = tf.data.Dataset.from_generator(\n    lambda: create_data_generator(val_image_paths, val_labels),\n    output_signature=(\n        tf.TensorSpec(shape=(*IMAGE_SIZE, 3), dtype=tf.float32),\n        tf.TensorSpec(shape=(), dtype=tf.float32)\n    )\n).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compile the model\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\nvgg_model_l2.compile(\n    optimizer=optimizer,\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\n# Compute steps per epoch\nsteps_per_epoch = len(train_df) // BATCH_SIZE\nvalidation_steps = len(val_df) // BATCH_SIZE\n\n# Set callbacks\ncallbacks_list = [\n    callbacks.EarlyStopping(\n        monitor='val_loss',\n        patience=3,\n        restore_best_weights=True\n    ),\n    callbacks.ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.2,\n        patience=3,\n        min_lr=1e-6\n    ),\n    callbacks.ModelCheckpoint(\n        filepath='best_vgg_model_l2.keras',\n        monitor='val_accuracy',\n        save_best_only=True,\n        verbose=1\n    )\n]\n\n# Train the model\nvgg_history_l2 = vgg_model_l2.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=10,\n    validation_steps=validation_steps,\n    steps_per_epoch=steps_per_epoch,\n    callbacks=callbacks_list\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Accuracy plot\nplt.figure(figsize=(10, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(vgg_history_l2.history['accuracy'], label='Train Accuracy')\nplt.plot(vgg_history_l2.history['val_accuracy'], label='Val Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Loss plot\nplt.subplot(1, 2, 2)\nplt.plot(vgg_history_l2.history['loss'], label='Train Loss')\nplt.plot(vgg_history_l2.history['val_loss'], label='Val Loss')\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can observe that the validation accuracy increases alongside the training accuracy, and the same trend appears in the loss values. This parallel movement indicates that our final tuning was effective. However, the presence of multiple spikes suggests the training process is still quite noisy and unstable at times.","metadata":{}},{"cell_type":"code","source":"y_true_vgg, y_pred_vgg, y_pred_probs_vgg = get_y_true_and_y_pred(val_dataset, vgg_model_l2, 0.5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ncm = confusion_matrix(y_true_vgg, y_pred_vgg)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot(cmap='Blues')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We have reduced a few of the false negatives, but there are still plenty, which signify that this would still not be good enough for medical purposes.\n\n","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\n\n# Get all .tif filenames from the test folder\ntest_dir = \"/kaggle/input/histopathologic-cancer-detection/test/\"\ntest_filenames = sorted([f for f in os.listdir(test_dir) if f.endswith(\".tif\")])\n\n# Extract IDs by removing \".tif\"\ntest_ids = [f[:-4] for f in test_filenames]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport cv2\nimport numpy as np\nimport os\n\ndef load_image_cv2(path, target_size=(96, 96)):\n    img = cv2.imread(path)  # BGR format\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n    img = cv2.resize(img, target_size)  # Resize\n    img = img.astype(np.float32) / 255.0  # Normalize to [0,1]\n    return img\n\ndef test_data_generator(paths):\n    for path in paths:\n        img = load_image_cv2(path)\n        yield img\n\n# Assuming test_dir and test_filenames already defined\ntest_paths = [os.path.join(test_dir, fname) for fname in test_filenames]\n\ntest_dataset = tf.data.Dataset.from_generator(\n    lambda: test_data_generator(test_paths),\n    output_signature=tf.TensorSpec(shape=(96, 96, 3), dtype=tf.float32)\n).batch(32).prefetch(tf.data.AUTOTUNE)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nimport numpy as np\n\n# Load the best saved VGG model with L2 regularization\nbest_vgg_model_l2 = load_model('best_vgg_model_l2.keras')\n\n# Predict probabilities on the test dataset\npred_probs = best_vgg_model_l2.predict(test_dataset, verbose=1)\n\n# Convert probabilities to binary predictions using threshold = 0.5\npred_labels = (pred_probs > 0.5).astype(int).flatten()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_df = pd.DataFrame({\n    'id': test_ids,\n    'label': pred_labels\n})\n\nsubmission_df.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import recall_score, accuracy_score\nfrom tensorflow.keras.models import load_model\n\ndef get_y_true_and_y_pred(val_dataset, model, threshold=0.5):\n    y_true = []\n    y_pred_probs = []\n\n    for batch_x, batch_y in val_dataset:\n        preds = model.predict(batch_x, verbose=0)\n        y_pred_probs.extend(preds.ravel())  # Flatten predicted probabilities\n        y_true.extend(batch_y.numpy().ravel())  # Convert labels from tensor to NumPy array\n\n    y_true = np.array(y_true)\n    y_pred_probs = np.array(y_pred_probs)\n    y_pred = (y_pred_probs > threshold).astype(int)\n\n    return y_true, y_pred\n\nbasic_model = load_model('best_basic_model.keras')\ny_true_bm, y_pred_bm = get_y_true_and_y_pred(val_dataset, basic_model, 0.5)\n\nbm_rc = recall_score(y_true_bm, y_pred_bm)\nbm_ac = accuracy_score(y_true_bm, y_pred_bm)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import recall_score, accuracy_score\nfrom tensorflow.keras.models import load_model\n\nvgg_model = load_model('best_vgg_model.keras')\ny_true_vgg, y_pred_vgg = get_y_true_and_y_pred(val_dataset, vgg_model, 0.5)\n\nvgg_rc = recall_score(y_true_vgg, y_pred_vgg)\nvgg_ac = accuracy_score(y_true_vgg, y_pred_vgg)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import recall_score, accuracy_score\nfrom tensorflow.keras.models import load_model\n\nvgg_model_lr = load_model('best_vgg_model_v1.keras')\ny_true_vgg_lr, y_pred_vgg_lr = get_y_true_and_y_pred(val_dataset, vgg_model_lr, 0.5)\n\nvgg_lr_rc = recall_score(y_true_vgg_lr, y_pred_vgg_lr)\nvgg_lr_ac = accuracy_score(y_true_vgg_lr, y_pred_vgg_lr)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import recall_score, accuracy_score\nfrom tensorflow.keras.models import load_model\n\nvgg_model_v2 = load_model('best_vgg_model_l2.keras')\ny_true_vgg_v2, y_pred_vgg_v2 = get_y_true_and_y_pred(val_dataset, vgg_model_l2, 0.5)\n\nvgg_v2_rc = recall_score(y_true_vgg_v2, y_pred_vgg_v2)\nvgg_v2_ac = accuracy_score(y_true_vgg_v2, y_pred_vgg_v2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = {\n    'Model': ['Basic Model', 'VGG Model', 'VGG Model with 1e-4 LR', 'VGG Model l2'],\n    'Accuracy': [bm_ac, vgg_ac, vgg_lr_ac, vgg_v2_ac],\n    'Recall': [bm_rc, vgg_rc, vgg_lr_rc, vgg_v2_rc],\n    'Miss Rate': [1 - bm_rc, 1 - vgg_rc, 1 - vgg_lr_rc, 1 - vgg_v2_rc,]\n}\n\ndf_result = pd.DataFrame(results).sort_values(by=['Miss Rate'], ascending=True)\ndf_result","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Learning and Takeaways**\n\nThroughout today’s work, it was clear that applying L2 regularization and dropout helped reduce overfitting and improved the model’s performance compared to the initial version. However, there is still room for enhancement. I have yet to experiment with different optimizers, which might lead to better convergence. Additionally, the current dataset size was limited to accommodate Kaggle’s environment constraints, so increasing the dataset or using data augmentation could further boost results. Exploring deeper or alternative architectures like InceptionNet or ResNet might also help, as well as extending the number of training epochs for more thorough learning.\n\n**Results**\n\nThe current model achieved a decent validation accuracy and demonstrated stable training behavior, but it still isn’t fully reliable for real-world applications, especially in sensitive domains like medical imaging. With more fine-tuning, optimizer experimentation, and possibly larger or augmented datasets, the model’s robustness and accuracy can be improved. Overall, this process has laid a solid foundation and clear next steps toward developing a more trustworthy model.","metadata":{}},{"cell_type":"markdown","source":"**GitHub repo URL**\nhttps://github.com/bopo80776288/CNN-Cancer-Detection.git","metadata":{}}]}